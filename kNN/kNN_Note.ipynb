{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## k-近邻算法\n",
    "###  kNN属于较为典型的监督学习算法，即已知训练集中数据的标签。\n",
    "> 假设存在训练集***R***，将输入的数据与训练集中的样本作特征值的比对，计算他们之间的距离(欧式距离、曼哈顿距离等)，\n",
    "> 选取距离最小(也就是相似度最高)的k个样本，将这k个样本的标签取出，其中出现频率最高的标签即为输入数据的预测标签。"
   ],
   "id": "fb59bbfa134bcdbe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import operator\n",
    "def kNearestNeighborClassifier(inputData, dataSet, labels, k):\n",
    "    \"\"\"\n",
    "    k-近邻算法\n",
    "    :param inputData: 输入的数据\n",
    "    :param dataSet:   训练集\n",
    "    :param labels:    标签列表\n",
    "    :param k:         近邻数量\n",
    "    :return:          分类结果\n",
    "    \"\"\"\n",
    "    # 获取数据集的大小，样本集为样本数据的特征矩阵，该特征矩阵的每一个行向量都代表了一个样本，故此处只需要获得行数即可表示数据集的大小\n",
    "    dataSize = dataSet.shape[0]\n",
    "    \n",
    "    # 计算距离，这里采用欧式距离\n",
    "    diffMat = tile(inputData, (dataSize, 1)) - dataSet\n",
    "    squaredDiffMat = diffMat ** 2\n",
    "    squaredDistances = squaredDiffMat.sum(axis=1)\n",
    "    distances = squaredDistances ** 0.5\n",
    "    \n",
    "    # 距离从小到大排序\n",
    "    sortedDistances = distances.argsort()\n",
    "    classCount = {}\n",
    "    # 统计k个近邻中的类别\n",
    "    for i in range(k):\n",
    "        voteLabel = labels[sortedDistances[i]]\n",
    "        classCount[voteLabel] = classCount.get(voteLabel, 0)\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 归一化思想\n",
    "> 从算法原理可以看出，kNN算法在计算距离时，(特别是欧氏距离)如果特征值向量中某一维度的特征值比其他维度的要大得多时，\n",
    "> 这个特征值对计算出的距离(相似度)的影响会更大，导致其他特征值的比重降低，因此需要对特征值进行归一化处理。   \n",
    "> 公式为: ***val_norm = (val - min_val)/(max_val - min_val)***"
   ],
   "id": "43d36fae8be4316"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def normalize(dataSet):\n",
    "    \"\"\"\n",
    "    归一化处理\n",
    "    :param dataSet: 原始的数据集\n",
    "    :return: 归一化后的数据集，范围向量，最小值向量，后两个参数用于输入数据的归一化\n",
    "    \"\"\"\n",
    "    # 计算每一列(即每个特征值列向量的最大值和最小值)\n",
    "    minVals = dataSet.min(0)\n",
    "    maxVals = dataSet.max(0)\n",
    "    # 求出每列特征值的取值范围\n",
    "    ranges = maxVals - minVals\n",
    "    # 归一化处理，创建一个空的归一化矩阵\n",
    "    normDataSet = zeros(shape(dataSet))\n",
    "    # 获得样本数量\n",
    "    m = dataSet.shape[0]\n",
    "    # 所有的特征值都减去当前列特征值最小值，然后除于当前特征值范围，得到归一化值\n",
    "    normDataSet = dataSet - tile(minVals, (m, 1))\n",
    "    normDataSet = normDataSet / tile(ranges, (m, 1))\n",
    "    return normDataSet, ranges, minVals"
   ],
   "id": "13649604fbc352ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
